{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Case Study 2: Predicting E-Commerce Product Recommendation Ratings from Reviews </h1></center> \n",
    "\n",
    "![](clothing_banner.jpg)\n",
    "\n",
    "This is a classic NLP problem dealing with data from an e-commerce store focusing on women's clothing. Each record in the dataset is a customer review which consists of the review title, text description and a rating (ranging from 1 - 5) for a product amongst other features\n",
    "\n",
    "We convert this into a binary classification problem such that a customer recommends a product (label 1) is the rating is > 3 else they do not recommend the product (label 0)\n",
    "\n",
    "__Main Objective:__ Leverage the review text attributes to predict the recommendation rating (classification)\n",
    "\n",
    "\n",
    "_Author: Dipanjan (DJ) Sarkar_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up basic dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import model_evaluation_utils as meu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and View the Dataset\n",
    "\n",
    "The data is available at https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews from where you can download it.\n",
    "\n",
    "You can also access it from my [__GitHub Repo__](https://github.com/dipanjanS/feature_engineering_session_dhs18) if needed.\n",
    "\n",
    "We recommend using the kaggle API and the following command via CLI to get it.\n",
    "\n",
    "__`kaggle datasets download -d nicapotato/womens-ecommerce-clothing-reviews`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td></td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                            \n",
       "1           1         1080   34                            \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Womens Clothing E-Commerce Reviews.csv', keep_default_na=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Data Processing\n",
    "\n",
    "- Merge all review text attributes (title, text description) into one attribute\n",
    "- Convert the 5-star rating system into a binary recommendation rating of 1 or 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some major design flaws I had such high hopes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My favorite buy! I love, love, love this jumps...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Flattering shirt This shirt is very flattering...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  Absolutely wonderful - silky and sexy and comf...       1\n",
       "1  Love this dress!  it's sooo pretty.  i happene...       1\n",
       "2  Some major design flaws I had such high hopes ...       0\n",
       "3  My favorite buy! I love, love, love this jumps...       1\n",
       "4  Flattering shirt This shirt is very flattering...       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Review'] = (df['Title'].map(str) +' '+ df['Review Text']).apply(lambda row: row.strip())\n",
    "df['Rating'] = [1 if rating > 3 else 0 for rating in df['Rating']]\n",
    "df = df[['Review', 'Rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove all records with no review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 22642 entries, 0 to 23485\n",
      "Data columns (total 2 columns):\n",
      "Review    22642 non-null object\n",
      "Rating    22642 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 530.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = df[df['Review'] != '']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is some imbalance in the data based on product ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    17449\n",
       "0     5193\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16981, 1), (5661, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Review']], df['Rating'])\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1: 13073, 0: 3908}), Counter({0: 1285, 1: 4376}))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Basic NLP Count based Features\n",
    "\n",
    "A number of basic text based features can also be created which sometimes are helpful for improving text classification models. \n",
    "Some examples are:\n",
    "\n",
    "- __Word Count:__ total number of words in the documents\n",
    "- __Character Count:__ total number of characters in the documents\n",
    "- __Average Word Density:__ average length of the words used in the documents\n",
    "- __Puncutation Count:__ total number of punctuation marks in the documents\n",
    "- __Upper Case Count:__ total number of upper count words in the documents\n",
    "- __Title Word Count:__ total number of proper case (title) words in the documents\n",
    "\n",
    "Source: https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "X_train['char_count'] = X_train['Review'].apply(len)\n",
    "X_train['word_count'] = X_train['Review'].apply(lambda x: len(x.split()))\n",
    "X_train['word_density'] = X_train['char_count'] / (X_train['word_count']+1)\n",
    "X_train['punctuation_count'] = X_train['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_train['title_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_train['upper_case_word_count'] = X_train['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n",
    "\n",
    "\n",
    "X_test['char_count'] = X_test['Review'].apply(len)\n",
    "X_test['word_count'] = X_test['Review'].apply(lambda x: len(x.split()))\n",
    "X_test['word_density'] = X_test['char_count'] / (X_test['word_count']+1)\n",
    "X_test['punctuation_count'] = X_test['Review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n",
    "X_test['title_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n",
    "X_test['upper_case_word_count'] = X_test['Review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>title_word_count</th>\n",
       "      <th>upper_case_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>I love these jeans! I'm curvy, have very muscu...</td>\n",
       "      <td>519</td>\n",
       "      <td>97</td>\n",
       "      <td>5.295918</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11370</th>\n",
       "      <td>Great on-trent dress! I bought this dress beca...</td>\n",
       "      <td>521</td>\n",
       "      <td>95</td>\n",
       "      <td>5.427083</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>Snug and unflattering Would be flattering on s...</td>\n",
       "      <td>392</td>\n",
       "      <td>72</td>\n",
       "      <td>5.369863</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13210</th>\n",
       "      <td>Super flattering, beautiful dress This is my f...</td>\n",
       "      <td>340</td>\n",
       "      <td>61</td>\n",
       "      <td>5.483871</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>Perfect, flattering sparrow jacket! I was in m...</td>\n",
       "      <td>538</td>\n",
       "      <td>94</td>\n",
       "      <td>5.663158</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  char_count  \\\n",
       "15465  I love these jeans! I'm curvy, have very muscu...         519   \n",
       "11370  Great on-trent dress! I bought this dress beca...         521   \n",
       "8158   Snug and unflattering Would be flattering on s...         392   \n",
       "13210  Super flattering, beautiful dress This is my f...         340   \n",
       "5483   Perfect, flattering sparrow jacket! I was in m...         538   \n",
       "\n",
       "       word_count  word_density  punctuation_count  title_word_count  \\\n",
       "15465          97      5.295918                 20                 1   \n",
       "11370          95      5.427083                 16                 2   \n",
       "8158           72      5.369863                 14                 2   \n",
       "13210          61      5.483871                 14                 2   \n",
       "5483           94      5.663158                 22                 2   \n",
       "\n",
       "       upper_case_word_count  \n",
       "15465                      1  \n",
       "11370                      1  \n",
       "8158                       0  \n",
       "13210                      0  \n",
       "5483                       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model \n",
    "\n",
    "A logistic regression model is easy to train, interpret and works well on a wide variety of NLP problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(C=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Metrics - Quick Refresher\n",
    "\n",
    "Just accuracy is never enough in datasets with a rare class problem.\n",
    "\n",
    "- __Precision:__ The positive predictive power of a model. Out of all the predictions made by a model for a class, how many are actually correct\n",
    "- __Recall:__ The coverage or hit-rate of a model. Out of all the test data samples belonging to a class, how many was the model able to predict (hit or cover) correctly.\n",
    "- __F1-score:__ The harmonic mean of the precision and recall\n",
    "\n",
    "Do check out ROC Curve, AUC Score and PR Curve also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      1.00      0.87      4376\n",
      "          0       0.00      0.00      0.00      1285\n",
      "\n",
      "avg / total       0.60      0.77      0.67      5661\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['Review'], axis=1), y_train)\n",
    "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our model was not able to predict a single product having a bad (no recommendation) rating, i.e. __Class 0__. \n",
    "\n",
    "This is as good as someone predicting a __1__ or __good__ for every product review. \n",
    "\n",
    "Can we do better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: NLP Count based features on Parts of Speech Tags\n",
    "\n",
    "This leverages Parts of Speech (POS) Tagging for text data and counting the total instances of the major parts of speech.\n",
    "Some examples are:\n",
    "\n",
    "- __Noun Count__\n",
    "- __Verb Count__\n",
    "- __Adjective Count__\n",
    "- __Adverb Count__\n",
    "- __Pronoun Count__\n",
    "\n",
    "Source: https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textblob\n",
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' :  ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "X_train['noun_count'] = X_train['Review'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "X_train['verb_count'] = X_train['Review'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "X_train['adj_count'] = X_train['Review'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "X_train['adv_count'] = X_train['Review'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "X_train['pron_count'] = X_train['Review'].apply(lambda x: check_pos_tag(x, 'pron'))\n",
    "\n",
    "X_test['noun_count'] = X_test['Review'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "X_test['verb_count'] = X_test['Review'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "X_test['adj_count'] = X_test['Review'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "X_test['adv_count'] = X_test['Review'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "X_test['pron_count'] = X_test['Review'].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping features from the previous experiment since they didn't help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(['char_count', 'word_count', 'word_density', \n",
    "              'punctuation_count', 'title_word_count', 'upper_case_word_count'], axis=1, inplace=True)\n",
    "X_test.drop(['char_count', 'word_count', 'word_density', \n",
    "              'punctuation_count', 'title_word_count', 'upper_case_word_count'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>I love these jeans! I'm curvy, have very muscu...</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11370</th>\n",
       "      <td>Great on-trent dress! I bought this dress beca...</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>Snug and unflattering Would be flattering on s...</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13210</th>\n",
       "      <td>Super flattering, beautiful dress This is my f...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>Perfect, flattering sparrow jacket! I was in m...</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  noun_count  \\\n",
       "15465  I love these jeans! I'm curvy, have very muscu...          19   \n",
       "11370  Great on-trent dress! I bought this dress beca...          21   \n",
       "8158   Snug and unflattering Would be flattering on s...          20   \n",
       "13210  Super flattering, beautiful dress This is my f...          15   \n",
       "5483   Perfect, flattering sparrow jacket! I was in m...          25   \n",
       "\n",
       "       verb_count  adj_count  adv_count  pron_count  \n",
       "15465          21          7         13          11  \n",
       "11370          24         15          6           4  \n",
       "8158           14          7          3           4  \n",
       "13210          16          9          3           4  \n",
       "5483           16         14          5           7  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.99      0.87      4376\n",
      "          0       0.52      0.04      0.07      1285\n",
      "\n",
      "avg / total       0.72      0.77      0.69      5661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['Review'], axis=1), y_train)\n",
    "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, looks like we are able to predict __4%__ of the total number of bad or negative rated products now! \n",
    "\n",
    "Performance for the good or positive rated products is unchanged and pretty decent but looks like the model is still biased towards predicting every product review as a good, recommended product. \n",
    "\n",
    "__F1-Score__ for bad reviews is a mere __7%__\n",
    "\n",
    "Can we improve on our model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging Text Sentiment\n",
    "\n",
    "Reviews are pretty subjective, opinionated and people often express stong emotions, feelings. \n",
    "This makes it a classic case where the text documents here are a good candidate for extracting sentiment as a feature.\n",
    "\n",
    "The general expectation is that highly rated and recommended products (__label 1__) should have a __positive__ sentiment and products which are not recommended (__label 0__) should have a __negative__ sentiment.\n",
    "\n",
    "TextBlob is an excellent open-source library for performing NLP tasks with ease, including sentiment analysis. It also an a sentiment lexicon (in the form of an XML file) which it leverages to give both polarity and subjectivity scores. \n",
    "\n",
    "- The polarity score is a float within the range [-1.0, 1.0]. \n",
    "- The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective. \n",
    "\n",
    "Perhaps this could be used for getting some new features? Let's look at some basic examples.\n",
    "\n",
    "Source: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.7500000000000001, subjectivity=0.9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob.TextBlob('This is an AMAZING pair of Jeans!').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.95, subjectivity=0.85)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblob.TextBlob('I really hated this UGLY T-shirt!!').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this should help us get features which can distinguish between good and bad products. Let's try it out on our dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: Features from Sentiment Analysis \n",
    "\n",
    "Remember this is unsupervised, lexicon-based sentiment analysis where we don't have any pre-labeled data saying which review migth have a positive or negative sentiment. We use the lexicon to determine this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_snt_obj = X_train['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_train['Polarity'] = [obj.polarity for obj in x_train_snt_obj.values]\n",
    "X_train['Subjectivity'] = [obj.polarity for obj in x_train_snt_obj.values]\n",
    "\n",
    "x_test_snt_obj = X_test['Review'].apply(lambda row: textblob.TextBlob(row).sentiment)\n",
    "X_test['Polarity'] = [obj.polarity for obj in x_test_snt_obj.values]\n",
    "X_test['Subjectivity'] = [obj.polarity for obj in x_test_snt_obj.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>I love these jeans! I'm curvy, have very muscu...</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0.335813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11370</th>\n",
       "      <td>Great on-trent dress! I bought this dress beca...</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0.392424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>Snug and unflattering Would be flattering on s...</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0.160119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13210</th>\n",
       "      <td>Super flattering, beautiful dress This is my f...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0.270417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>Perfect, flattering sparrow jacket! I was in m...</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0.444592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  noun_count  \\\n",
       "15465  I love these jeans! I'm curvy, have very muscu...          19   \n",
       "11370  Great on-trent dress! I bought this dress beca...          21   \n",
       "8158   Snug and unflattering Would be flattering on s...          20   \n",
       "13210  Super flattering, beautiful dress This is my f...          15   \n",
       "5483   Perfect, flattering sparrow jacket! I was in m...          25   \n",
       "\n",
       "       verb_count  adj_count  adv_count  pron_count  Polarity  Subjectivity  \n",
       "15465          21          7         13          11  0.335813      0.335813  \n",
       "11370          24         15          6           4  0.392424      0.392424  \n",
       "8158           14          7          3           4  0.160119      0.160119  \n",
       "13210          16          9          3           4  0.270417      0.270417  \n",
       "5483           16         14          5           7  0.444592      0.444592  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.83      0.96      0.89      4376\n",
      "          0       0.71      0.34      0.46      1285\n",
      "\n",
      "avg / total       0.80      0.82      0.79      5661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train.drop(['Review'], axis=1), y_train)\n",
    "predictions = lr.predict(X_test.drop(['Review'], axis=1))\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting! Looks like we are now able to predict __34%__ of the total number of bad or negative rated products now! \n",
    "Precision is quite good at __71%__\n",
    "\n",
    "__F1-Score__ for bad reviews is now __46%__ and good reviews is __89%__\n",
    "\n",
    "This brings our overall __F1-Score__ to __79%__ which is quite good.\n",
    "\n",
    "Can we still improve on our model since the recall of bad reviews is still pretty low?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing and Wrangling\n",
    "\n",
    "We want to extract some specific features based on standard NLP feature engineering models like the classic Bag of Words model.\n",
    "For this we need to clean and pre-process our text data. We will build a simple text pre-processor here since the main intent is to look at feature engineering strategies.\n",
    "\n",
    "We will focus on:\n",
    "- Text Lowercasing\n",
    "- Removal of contractions\n",
    "- Removing unnecessary characters, numbers and symbols\n",
    "- Stemming\n",
    "- Stopword removal\n",
    "\n",
    "Source: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I did not like this t-shirt'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import contractions\n",
    "\n",
    "contractions.fix('I didn\\'t like this t-shirt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import contractions\n",
    "import re\n",
    "\n",
    "# remove some stopwords to capture negation in n-grams if possible\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')\n",
    "stop_words.remove('but')\n",
    "\n",
    "# load up a simple porter stemmer - nothing fancy\n",
    "ps = nltk.porter.PorterStemmer()\n",
    "\n",
    "def simple_text_preprocessor(document): \n",
    "    # lower case\n",
    "    document = str(document).lower()\n",
    "    \n",
    "    # expand contractions\n",
    "    document = contractions.fix(document)\n",
    "    \n",
    "    # remove unnecessary characters\n",
    "    document = re.sub(r'[^a-zA-Z]',r' ', document)\n",
    "    document = re.sub(r'nbsp', r'', document)\n",
    "    document = re.sub(' +', ' ', document)\n",
    "    \n",
    "    # simple porter stemming\n",
    "    document = ' '.join([ps.stem(word) for word in document.split()])\n",
    "    \n",
    "    # stopwords removal\n",
    "    document = ' '.join([word for word in document.split() if word not in stop_words])\n",
    "    \n",
    "    return document\n",
    "\n",
    "stp = np.vectorize(simple_text_preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Clean Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15465</th>\n",
       "      <td>I love these jeans! I'm curvy, have very muscu...</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>love jean curvi veri muscular thigh wa not ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11370</th>\n",
       "      <td>Great on-trent dress! I bought this dress beca...</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>great trent dress bought thi dress becaus love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>Snug and unflattering Would be flattering on s...</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>snug unflatt would flatter someon slim right c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13210</th>\n",
       "      <td>Super flattering, beautiful dress This is my f...</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>super flatter beauti dress thi favorit dress b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5483</th>\n",
       "      <td>Perfect, flattering sparrow jacket! I was in m...</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>perfect flatter sparrow jacket wa local retail...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  noun_count  \\\n",
       "15465  I love these jeans! I'm curvy, have very muscu...          19   \n",
       "11370  Great on-trent dress! I bought this dress beca...          21   \n",
       "8158   Snug and unflattering Would be flattering on s...          20   \n",
       "13210  Super flattering, beautiful dress This is my f...          15   \n",
       "5483   Perfect, flattering sparrow jacket! I was in m...          25   \n",
       "\n",
       "       verb_count  adj_count  adv_count  pron_count  Polarity  Subjectivity  \\\n",
       "15465          21          7         13          11  0.335813      0.335813   \n",
       "11370          24         15          6           4  0.392424      0.392424   \n",
       "8158           14          7          3           4  0.160119      0.160119   \n",
       "13210          16          9          3           4  0.270417      0.270417   \n",
       "5483           16         14          5           7  0.444592      0.444592   \n",
       "\n",
       "                                            Clean Review  \n",
       "15465  love jean curvi veri muscular thigh wa not ver...  \n",
       "11370  great trent dress bought thi dress becaus love...  \n",
       "8158   snug unflatt would flatter someon slim right c...  \n",
       "13210  super flatter beauti dress thi favorit dress b...  \n",
       "5483   perfect flatter sparrow jacket wa local retail...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Clean Review'] = stp(X_train['Review'].values)\n",
    "X_test['Clean Review'] = stp(X_test['Review'].values)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting out the structured features from previous experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0.335813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0.392424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0.160119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0.270417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0.444592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   noun_count  verb_count  adj_count  adv_count  pron_count  Polarity  \\\n",
       "0          19          21          7         13          11  0.335813   \n",
       "1          21          24         15          6           4  0.392424   \n",
       "2          20          14          7          3           4  0.160119   \n",
       "3          15          16          9          3           4  0.270417   \n",
       "4          25          16         14          5           7  0.444592   \n",
       "\n",
       "   Subjectivity  \n",
       "0      0.335813  \n",
       "1      0.392424  \n",
       "2      0.160119  \n",
       "3      0.270417  \n",
       "4      0.444592  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_metadata = X_train.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
    "X_test_metadata = X_test.drop(['Review', 'Clean Review'], axis=1).reset_index(drop=True)\n",
    "\n",
    "X_train_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4: Adding Bag of Words based Features - 1-grams\n",
    "\n",
    "This is perhaps the most simple vector space representational model for unstructured text. A vector space model is simply a mathematical model to represent unstructured text (or any other data) as numeric vectors, such that each dimension of the vector is a specific feature\\attribute. \n",
    "\n",
    "The bag of words model represents each text document as a numeric vector where each dimension is a specific word from the corpus and the value could be its frequency in the document, occurrence (denoted by 1 or 0) or even weighted values. \n",
    "\n",
    "The model’s name is such because each document is represented literally as a ‘bag’ of its own words, disregarding word orders, sequences and grammar.\n",
    "\n",
    "Source: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaandido</th>\n",
       "      <th>aaaaannnnnnd</th>\n",
       "      <th>aaaah</th>\n",
       "      <th>aaaahmaz</th>\n",
       "      <th>aaah</th>\n",
       "      <th>aam</th>\n",
       "      <th>ab</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbi</th>\n",
       "      <th>...</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zowi</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8587 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaaaandido  aaaaannnnnnd  aaaah  aaaahmaz  aaah  aam  ab  abbey  abbi  \\\n",
       "0   0           0             0      0         0     0    0   0      0     0   \n",
       "1   0           0             0      0         0     0    0   0      0     0   \n",
       "2   0           0             0      0         0     0    0   0      0     0   \n",
       "3   0           0             0      0         0     0    0   0      0     0   \n",
       "4   0           0             0      0         0     0    0   0      0     0   \n",
       "\n",
       "   ...   ziploc  zipper  zipperi  zoe  zombi  zone  zooland  zoom  zowi  zuma  \n",
       "0  ...        0       0        0    0      0     0        0     0     0     0  \n",
       "1  ...        0       0        0    0      0     0        0     0     0     0  \n",
       "2  ...        0       0        0    0      0     0        0     0     0     0  \n",
       "3  ...        0       0        0    0      0     0        0     0     0     0  \n",
       "4  ...        0       0        0    0      0     0        0     0     0     0  \n",
       "\n",
       "[5 rows x 8587 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0.0, max_df=1.0, ngram_range=(1, 1))\n",
    "X_traincv = cv.fit_transform(X_train['Clean Review']).toarray()\n",
    "X_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names())\n",
    "\n",
    "X_testcv = cv.transform(X_test['Clean Review']).toarray()\n",
    "X_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names())\n",
    "X_traincv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaandido</th>\n",
       "      <th>aaaaannnnnnd</th>\n",
       "      <th>...</th>\n",
       "      <th>ziploc</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zipperi</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zooland</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zowi</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8594 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noun_count  verb_count  adj_count  adv_count  pron_count  Polarity  \\\n",
       "0          19          21          7         13          11  0.335813   \n",
       "1          21          24         15          6           4  0.392424   \n",
       "2          20          14          7          3           4  0.160119   \n",
       "3          15          16          9          3           4  0.270417   \n",
       "4          25          16         14          5           7  0.444592   \n",
       "\n",
       "   Subjectivity  aa  aaaaandido  aaaaannnnnnd  ...   ziploc  zipper  zipperi  \\\n",
       "0      0.335813   0           0             0  ...        0       0        0   \n",
       "1      0.392424   0           0             0  ...        0       0        0   \n",
       "2      0.160119   0           0             0  ...        0       0        0   \n",
       "3      0.270417   0           0             0  ...        0       0        0   \n",
       "4      0.444592   0           0             0  ...        0       0        0   \n",
       "\n",
       "   zoe  zombi  zone  zooland  zoom  zowi  zuma  \n",
       "0    0      0     0        0     0     0     0  \n",
       "1    0      0     0        0     0     0     0  \n",
       "2    0      0     0        0     0     0     0  \n",
       "3    0      0     0        0     0     0     0  \n",
       "4    0      0     0        0     0     0     0  \n",
       "\n",
       "[5 rows x 8594 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comb = pd.concat([X_train_metadata, X_traincv], axis=1)\n",
    "X_test_comb = pd.concat([X_test_metadata, X_testcv], axis=1)\n",
    "\n",
    "X_train_comb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.92      0.94      0.93      4376\n",
      "          0       0.77      0.71      0.74      1285\n",
      "\n",
      "avg / total       0.88      0.89      0.88      5661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_comb, y_train)\n",
    "predictions = lr.predict(X_test_comb)\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! This looks promising.\n",
    "\n",
    "We are now able to predict __71%__ of the total number of bad or negative rated products now! \n",
    "Precision is quite good at __77%__\n",
    "\n",
    "__F1-Score__ for bad reviews is now __74%__ and good reviews is __93%__\n",
    "\n",
    "This brings our overall __F1-Score__ to __88%__ which is quite good.\n",
    "\n",
    "Can we still improve on our model? Let's look at n-grams!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5: Adding Bag of Words based Features - 2-grams\n",
    "\n",
    "We use the same feature engineering technique here except we consider both 1 and 2-grams as our features. \n",
    "We also do some basic filtering like removing terms which might occur only once or almost in every document!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aa waist</th>\n",
       "      <th>ab</th>\n",
       "      <th>ab fab</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abdomen also</th>\n",
       "      <th>abil</th>\n",
       "      <th>abil dress</th>\n",
       "      <th>abl</th>\n",
       "      <th>abl bend</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper tri</th>\n",
       "      <th>zipper veri</th>\n",
       "      <th>zipper wa</th>\n",
       "      <th>zipper well</th>\n",
       "      <th>zipper work</th>\n",
       "      <th>zipper would</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone style</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoom close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63225 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aa waist  ab  ab fab  abdomen  abdomen also  abil  abil dress  abl  \\\n",
       "0   0         0   0       0        0             0     0           0    0   \n",
       "1   0         0   0       0        0             0     0           0    0   \n",
       "2   0         0   0       0        0             0     0           0    0   \n",
       "3   0         0   0       0        0             0     0           0    0   \n",
       "4   0         0   0       0        0             0     0           0    0   \n",
       "\n",
       "   abl bend     ...      zipper tri  zipper veri  zipper wa  zipper well  \\\n",
       "0         0     ...               0            0          0            0   \n",
       "1         0     ...               0            0          0            0   \n",
       "2         0     ...               0            0          0            0   \n",
       "3         0     ...               0            0          0            0   \n",
       "4         0     ...               0            0          0            0   \n",
       "\n",
       "   zipper work  zipper would  zone  zone style  zoom  zoom close  \n",
       "0            0             0     0           0     0           0  \n",
       "1            0             0     0           0     0           0  \n",
       "2            0             0     0           0     0           0  \n",
       "3            0             0     0           0     0           0  \n",
       "4            0             0     0           0     0           0  \n",
       "\n",
       "[5 rows x 63225 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=2, max_df=0.99, ngram_range=(1, 2))\n",
    "X_traincv = cv.fit_transform(X_train['Clean Review']).toarray()\n",
    "X_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names())\n",
    "\n",
    "X_testcv = cv.transform(X_test['Clean Review']).toarray()\n",
    "X_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names())\n",
    "X_traincv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>aa</th>\n",
       "      <th>aa waist</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper tri</th>\n",
       "      <th>zipper veri</th>\n",
       "      <th>zipper wa</th>\n",
       "      <th>zipper well</th>\n",
       "      <th>zipper work</th>\n",
       "      <th>zipper would</th>\n",
       "      <th>zone</th>\n",
       "      <th>zone style</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoom close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noun_count  verb_count  adj_count  adv_count  pron_count  Polarity  \\\n",
       "0          19          21          7         13          11  0.335813   \n",
       "1          21          24         15          6           4  0.392424   \n",
       "2          20          14          7          3           4  0.160119   \n",
       "3          15          16          9          3           4  0.270417   \n",
       "4          25          16         14          5           7  0.444592   \n",
       "\n",
       "   Subjectivity  aa  aa waist  ab     ...      zipper tri  zipper veri  \\\n",
       "0      0.335813   0         0   0     ...               0            0   \n",
       "1      0.392424   0         0   0     ...               0            0   \n",
       "2      0.160119   0         0   0     ...               0            0   \n",
       "3      0.270417   0         0   0     ...               0            0   \n",
       "4      0.444592   0         0   0     ...               0            0   \n",
       "\n",
       "   zipper wa  zipper well  zipper work  zipper would  zone  zone style  zoom  \\\n",
       "0          0            0            0             0     0           0     0   \n",
       "1          0            0            0             0     0           0     0   \n",
       "2          0            0            0             0     0           0     0   \n",
       "3          0            0            0             0     0           0     0   \n",
       "4          0            0            0             0     0           0     0   \n",
       "\n",
       "   zoom close  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "\n",
       "[5 rows x 63232 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comb = pd.concat([X_train_metadata, X_traincv], axis=1)\n",
    "X_test_comb = pd.concat([X_test_metadata, X_testcv], axis=1)\n",
    "\n",
    "X_train_comb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.92      0.95      0.94      4376\n",
      "          0       0.80      0.74      0.77      1285\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_comb, y_train)\n",
    "predictions = lr.predict(X_test_comb)\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see some clear improvements!\n",
    "\n",
    "We are now able to predict __74%__ of the total number of bad or negative rated products now! \n",
    "Precision is quite good at __80%__\n",
    "\n",
    "__F1-Score__ for bad reviews is now __77%__ and good reviews is __94%__\n",
    "\n",
    "This brings our overall __F1-Score__ to __90%__ which is excellent!\n",
    "\n",
    "Do note that introducing n-grams has really exploded our feature space! Can we reduce some of these features and still maintain an equal level of performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some intelligence feature selection\n",
    "\n",
    "We plot the CDF of the proportion of words occuring in a specific number of documents to really get an idea of how many features are occuring in how many documents.\n",
    "\n",
    "This should help us tweak the `__min_df__` or `__max_df__` hyperparameters a bit when doing feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Doc Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aa waist</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ab</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab fab</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abdomen</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abdomen also</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>abil</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>abil dress</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>abl</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>abl bend</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Doc Freq\n",
       "0            aa        12\n",
       "1      aa waist         3\n",
       "2            ab         7\n",
       "3        ab fab         3\n",
       "4       abdomen         5\n",
       "5  abdomen also         2\n",
       "6          abil         9\n",
       "7    abil dress         2\n",
       "8           abl       318\n",
       "9      abl bend         2"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_doc_freq = X_traincv.sum(axis=0).transpose().reset_index()\n",
    "word_doc_freq.columns = ['Word', 'Doc Freq']\n",
    "word_doc_freq.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "fig = plt.figure(facecolor='white', figsize=(20, 10))\n",
    "plt.rcParams['axes.facecolor']='white'\n",
    "plt.rcParams['axes.edgecolor']='white'\n",
    "\n",
    "x_ax = np.sort(word_doc_freq['Doc Freq'])\n",
    "y_ax = np.arange(1, len(x_ax)+1)/len(x_ax)\n",
    "plt.plot(x_ax , y_ax, linewidth=0.8, color='r')\n",
    "\n",
    "plt.xlim(-1, 100)\n",
    "_ = plt.xlabel('Number of Documents')\n",
    "_ = plt.ylabel('CDF of Word Freq.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 24784),\n",
       " (3, 10813),\n",
       " (4, 5922),\n",
       " (5, 3916),\n",
       " (6, 2651),\n",
       " (7, 1995),\n",
       " (8, 1427),\n",
       " (9, 1130),\n",
       " (10, 969),\n",
       " (11, 793)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(x_ax).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6: Adding Bag of Words based Features - 2-grams with Feature Selection\n",
    "\n",
    "We use the same feature engineering technique here except we consider both 1 and 2-grams as our features. \n",
    "We remove words occuring only twice since there seems to be a huge number of such words increasing the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aa waist</th>\n",
       "      <th>ab</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abl button</th>\n",
       "      <th>abl buy</th>\n",
       "      <th>abl dress</th>\n",
       "      <th>abl easili</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper side</th>\n",
       "      <th>zipper stick</th>\n",
       "      <th>zipper thi</th>\n",
       "      <th>zipper top</th>\n",
       "      <th>zipper veri</th>\n",
       "      <th>zipper wa</th>\n",
       "      <th>zipper well</th>\n",
       "      <th>zipper would</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aa waist  ab  abdomen  abil  abl  abl button  abl buy  abl dress  \\\n",
       "0   0         0   0        0     0    0           0        0          0   \n",
       "1   0         0   0        0     0    0           0        0          0   \n",
       "2   0         0   0        0     0    0           0        0          0   \n",
       "3   0         0   0        0     0    0           0        0          0   \n",
       "4   0         0   0        0     0    0           0        0          0   \n",
       "\n",
       "   abl easili  ...   zipper side  zipper stick  zipper thi  zipper top  \\\n",
       "0           0  ...             0             0           0           0   \n",
       "1           0  ...             0             0           0           0   \n",
       "2           0  ...             0             0           0           0   \n",
       "3           0  ...             0             0           0           0   \n",
       "4           0  ...             0             0           0           0   \n",
       "\n",
       "   zipper veri  zipper wa  zipper well  zipper would  zone  zoom  \n",
       "0            0          0            0             0     0     0  \n",
       "1            0          0            0             0     0     0  \n",
       "2            0          0            0             0     0     0  \n",
       "3            0          0            0             0     0     0  \n",
       "4            0          0            0             0     0     0  \n",
       "\n",
       "[5 rows x 38173 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=3, max_df=0.99, ngram_range=(1, 2))\n",
    "X_traincv = cv.fit_transform(X_train['Clean Review']).toarray()\n",
    "X_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names())\n",
    "\n",
    "X_testcv = cv.transform(X_test['Clean Review']).toarray()\n",
    "X_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names())\n",
    "X_traincv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>aa</th>\n",
       "      <th>aa waist</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper side</th>\n",
       "      <th>zipper stick</th>\n",
       "      <th>zipper thi</th>\n",
       "      <th>zipper top</th>\n",
       "      <th>zipper veri</th>\n",
       "      <th>zipper wa</th>\n",
       "      <th>zipper well</th>\n",
       "      <th>zipper would</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noun_count  verb_count  adj_count  adv_count  pron_count  Polarity  \\\n",
       "0          19          21          7         13          11  0.335813   \n",
       "1          21          24         15          6           4  0.392424   \n",
       "2          20          14          7          3           4  0.160119   \n",
       "3          15          16          9          3           4  0.270417   \n",
       "4          25          16         14          5           7  0.444592   \n",
       "\n",
       "   Subjectivity  aa  aa waist  ab  ...   zipper side  zipper stick  \\\n",
       "0      0.335813   0         0   0  ...             0             0   \n",
       "1      0.392424   0         0   0  ...             0             0   \n",
       "2      0.160119   0         0   0  ...             0             0   \n",
       "3      0.270417   0         0   0  ...             0             0   \n",
       "4      0.444592   0         0   0  ...             0             0   \n",
       "\n",
       "   zipper thi  zipper top  zipper veri  zipper wa  zipper well  zipper would  \\\n",
       "0           0           0            0          0            0             0   \n",
       "1           0           0            0          0            0             0   \n",
       "2           0           0            0          0            0             0   \n",
       "3           0           0            0          0            0             0   \n",
       "4           0           0            0          0            0             0   \n",
       "\n",
       "   zone  zoom  \n",
       "0     0     0  \n",
       "1     0     0  \n",
       "2     0     0  \n",
       "3     0     0  \n",
       "4     0     0  \n",
       "\n",
       "[5 rows x 38180 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comb = pd.concat([X_train_metadata, X_traincv], axis=1)\n",
    "X_test_comb = pd.concat([X_test_metadata, X_testcv], axis=1)\n",
    "\n",
    "X_train_comb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.92      0.94      0.93      4376\n",
      "          0       0.80      0.73      0.76      1285\n",
      "\n",
      "avg / total       0.89      0.90      0.90      5661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_comb, y_train)\n",
    "predictions = lr.predict(X_test_comb)\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have almost cut down our feature space by half but our overall model performance is still approximately the same which is good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7: Adding Bag of Words based Features - 3-grams with Feature Selection\n",
    "\n",
    "We use the same feature engineering technique here except we consider 1, 2 and 3-grams as our features. \n",
    "Feature selection is done just like the previous experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aa waist</th>\n",
       "      <th>ab</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abl button</th>\n",
       "      <th>abl buy</th>\n",
       "      <th>abl dress</th>\n",
       "      <th>abl easili</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper thi</th>\n",
       "      <th>zipper top</th>\n",
       "      <th>zipper veri</th>\n",
       "      <th>zipper wa</th>\n",
       "      <th>zipper wa not</th>\n",
       "      <th>zipper well</th>\n",
       "      <th>zipper would</th>\n",
       "      <th>zipper would not</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55574 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aa waist  ab  abdomen  abil  abl  abl button  abl buy  abl dress  \\\n",
       "0   0         0   0        0     0    0           0        0          0   \n",
       "1   0         0   0        0     0    0           0        0          0   \n",
       "2   0         0   0        0     0    0           0        0          0   \n",
       "3   0         0   0        0     0    0           0        0          0   \n",
       "4   0         0   0        0     0    0           0        0          0   \n",
       "\n",
       "   abl easili  ...   zipper thi  zipper top  zipper veri  zipper wa  \\\n",
       "0           0  ...            0           0            0          0   \n",
       "1           0  ...            0           0            0          0   \n",
       "2           0  ...            0           0            0          0   \n",
       "3           0  ...            0           0            0          0   \n",
       "4           0  ...            0           0            0          0   \n",
       "\n",
       "   zipper wa not  zipper well  zipper would  zipper would not  zone  zoom  \n",
       "0              0            0             0                 0     0     0  \n",
       "1              0            0             0                 0     0     0  \n",
       "2              0            0             0                 0     0     0  \n",
       "3              0            0             0                 0     0     0  \n",
       "4              0            0             0                 0     0     0  \n",
       "\n",
       "[5 rows x 55574 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(min_df=3, max_df=0.99, ngram_range=(1, 3))\n",
    "X_traincv = cv.fit_transform(X_train['Clean Review']).toarray()\n",
    "X_traincv = pd.DataFrame(X_traincv, columns=cv.get_feature_names())\n",
    "\n",
    "X_testcv = cv.transform(X_test['Clean Review']).toarray()\n",
    "X_testcv = pd.DataFrame(X_testcv, columns=cv.get_feature_names())\n",
    "X_traincv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>aa</th>\n",
       "      <th>aa waist</th>\n",
       "      <th>ab</th>\n",
       "      <th>...</th>\n",
       "      <th>zipper thi</th>\n",
       "      <th>zipper top</th>\n",
       "      <th>zipper veri</th>\n",
       "      <th>zipper wa</th>\n",
       "      <th>zipper wa not</th>\n",
       "      <th>zipper well</th>\n",
       "      <th>zipper would</th>\n",
       "      <th>zipper would not</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0.335813</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0.392424</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0.160119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0.444592</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55581 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   noun_count  verb_count  adj_count  adv_count  pron_count  Polarity  \\\n",
       "0          19          21          7         13          11  0.335813   \n",
       "1          21          24         15          6           4  0.392424   \n",
       "2          20          14          7          3           4  0.160119   \n",
       "3          15          16          9          3           4  0.270417   \n",
       "4          25          16         14          5           7  0.444592   \n",
       "\n",
       "   Subjectivity  aa  aa waist  ab  ...   zipper thi  zipper top  zipper veri  \\\n",
       "0      0.335813   0         0   0  ...            0           0            0   \n",
       "1      0.392424   0         0   0  ...            0           0            0   \n",
       "2      0.160119   0         0   0  ...            0           0            0   \n",
       "3      0.270417   0         0   0  ...            0           0            0   \n",
       "4      0.444592   0         0   0  ...            0           0            0   \n",
       "\n",
       "   zipper wa  zipper wa not  zipper well  zipper would  zipper would not  \\\n",
       "0          0              0            0             0                 0   \n",
       "1          0              0            0             0                 0   \n",
       "2          0              0            0             0                 0   \n",
       "3          0              0            0             0                 0   \n",
       "4          0              0            0             0                 0   \n",
       "\n",
       "   zone  zoom  \n",
       "0     0     0  \n",
       "1     0     0  \n",
       "2     0     0  \n",
       "3     0     0  \n",
       "4     0     0  \n",
       "\n",
       "[5 rows x 55581 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_comb = pd.concat([X_train_metadata, X_traincv], axis=1)\n",
    "X_test_comb = pd.concat([X_test_metadata, X_testcv], axis=1)\n",
    "\n",
    "X_train_comb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.93      0.95      0.94      4376\n",
      "          0       0.81      0.74      0.77      1285\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5661\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train_comb, y_train)\n",
    "predictions = lr.predict(X_test_comb)\n",
    "meu.display_classification_report(true_labels=y_test, predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a standard peformance like the previous models with maybe a __1%__ increase in precision and recall for the poorly rated products. \n",
    "\n",
    "Overall __F1-Score__ remains constant at __90%__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Scope\n",
    "\n",
    "Try out TF-IDF, word embedding based features, topic model based features, undersampling and oversampling (synthetic sampling), deep learning models and so on!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
